# Triple GPU + Triple TTS Video Generation System

## ğŸš€ Overview

This webapp provides **high-performance video generation** with dedicated TTS services for each GPU:

- **GPU 0** (Port 8390) â†’ **TTS 0** (Port 18182)
- **GPU 1** (Port 8391) â†’ **TTS 1** (Port 18183)
- **GPU 2** (Port 8392) â†’ **TTS 2** (Port 18184)
- **Web API** running on **Port 5003**

## âœ¨ Key Features

âœ… **3 GPUs, 3 TTS Services** - Maximum throughput!  
âœ… **Smart Queue Management** - Automatic task distribution  
âœ… **Dedicated TTS per GPU** - No bottlenecks  
âœ… **Real-time Status** - Monitor all GPUs and queue  
âœ… **Modern Web UI** - Drag & drop interface  
âœ… **Text Normalization** - LaTeX/Math conversion support

---

## ğŸ—ï¸ Architecture

```
User Request (Video + Text)
    â†“
Extract Audio from Video
    â†“
[Smart GPU Selection - 3 GPUs Available]
    â†“
GPU 0 Free â†’ Use TTS Port 18182
GPU 1 Free â†’ Use TTS Port 18183
GPU 2 Free â†’ Use TTS Port 18184
    â†“
Generate Voice Clone (Dedicated TTS)
    â†“
Queue to Available GPU
    â†“
Process Video
    â†“
Return Result
```

**Advantage**: Each GPU has its own TTS service, so:
- No waiting for shared TTS
- True parallel processing (3 videos simultaneously)
- 50% faster than dual GPU setup

---

## ğŸ“¦ Prerequisites

### 1. Docker Containers Required

You need **6 Docker containers** running:

**GPU Containers:**
```bash
heygem-gpu0  â†’ Port 8390 (GPU 0)
heygem-gpu1  â†’ Port 8391 (GPU 1)
heygem-gpu2  â†’ Port 8392 (GPU 2)
```

**TTS Containers:**
```bash
heygem-tts-dual-0 â†’ Port 18182 (Fish-Speech for GPU 0)
heygem-tts-dual-1 â†’ Port 18183 (Fish-Speech for GPU 1)
heygem-tts-dual-2 â†’ Port 18184 (Fish-Speech for GPU 2)
```

### 2. System Requirements

- **3 NVIDIA GPUs** (RTX A5000 or similar)
- **Docker** with NVIDIA runtime
- **Python 3.8+** with Flask
- **FFmpeg** for audio/video processing

---

## ğŸ¬ How to Run

### Step 1: Create Data Directories

```bash
# Create data directories for all GPUs and TTS services
mkdir -p ~/heygem_data/{gpu0,gpu1,gpu2,tts0,tts1,tts2}
```

### Step 2: Start Docker Containers

```bash
# Navigate to project directory
cd /nvme0n1-disk/nvme01/HeyGem

# Start all containers
docker compose -f docker-compose-dual-tts.yml up -d

# Verify all 6 containers are running
docker ps --filter "name=heygem"
```

You should see:
```
heygem-gpu0
heygem-gpu1
heygem-gpu2
heygem-tts-dual-0
heygem-tts-dual-1
heygem-tts-dual-2
```

### Step 3: Install Python Dependencies

```bash
cd webapp_dual_tts
pip install -r requirements.txt
```

### Step 4: Start the Web Server

```bash
# Using systemd service (recommended)
sudo systemctl start heygem-dual-tts
sudo systemctl enable heygem-dual-tts  # Auto-start on boot

# OR manually
python3 app.py
```

### Step 5: Open Browser

```
http://localhost:5003
```

---

## ğŸ”Œ API Endpoints

### 1. Generate Video
```bash
POST /api/generate
Content-Type: multipart/form-data

Fields:
  - video: Video file (optional)
  - text: Text to speak (required)

Response:
{
  "success": true,
  "task_id": "task_1234567890",
  "status_url": "/api/status/task_1234567890"
}
```

### 2. Check Status
```bash
GET /api/status/{task_id}

Response:
{
  "status": "processing|completed|failed|queued",
  "progress": 0-100,
  "gpu_id": 0|1|2,
  "timing": {
    "tts_time": 26.5,
    "video_time": 65.3,
    "total_time": 91.8
  }
}
```

### 3. Get Queue Status
```bash
GET /api/queue

Response:
{
  "gpus": {
    "0": {"busy": true, "current_task": "task_123", ...},
    "1": {"busy": false, "current_task": null, ...},
    "2": {"busy": true, "current_task": "task_456", ...}
  },
  "queue": [],
  "queue_size": 0
}
```

### 4. Download Video
```bash
GET /api/download/{task_id}
```

### 5. API Info
```bash
GET /api/info

Response:
{
  "service": "Triple GPU + Triple TTS Video Generation",
  "gpus": {
    "0": {"video_port": 8390, "tts_port": 18182},
    "1": {"video_port": 8391, "tts_port": 18183},
    "2": {"video_port": 8392, "tts_port": 18184}
  }
}
```

---

## ğŸ“Š Performance Comparison

| Setup | GPUs | TTS Services | Max Parallel Videos | Throughput |
|-------|------|--------------|---------------------|------------|
| Single GPU | 1 | 1 | 1 video | Baseline |
| Dual GPU | 2 | 2 | 2 videos | 2x faster |
| **Triple GPU** | **3** | **3** | **3 videos** | **3x faster** |

---

## ğŸ§ª Testing

### Test with cURL

```bash
# Test all TTS services
curl -X POST http://localhost:18182/v1/health
curl -X POST http://localhost:18183/v1/health
curl -X POST http://localhost:18184/v1/health

# Submit video generation
curl -X POST http://localhost:5003/api/generate \
  -F "video=@test.mp4" \
  -F "text=Hello, this is a test"

# Check status
curl http://localhost:5003/api/status/task_xxxxx

# View queue
curl http://localhost:5003/api/queue
```

### Test 3 Parallel Tasks

```bash
# Submit 3 tasks simultaneously
for i in {1..3}; do
  curl -X POST http://localhost:5003/api/generate \
    -F "text=Test video $i" &
done

# All 3 should process in parallel (no queue)
curl http://localhost:5003/api/queue
```

---

## ğŸ”§ Configuration

### GPU Assignment

Edit `dual_gpu_scheduler.py`:

```python
self.gpu_config = {
    0: {
        "port": 8390,      # Video generation port
        "tts_port": 18182, # Dedicated TTS port
        "busy": False
    },
    1: {
        "port": 8391,
        "tts_port": 18183,
        "busy": False
    },
    2: {
        "port": 8392,
        "tts_port": 18184,
        "busy": False
    }
}
```

### Timeout Settings

```python
max_wait = 1800  # 30 minutes
check_interval = 5  # Check every 5 seconds
```

---

## ğŸ› Troubleshooting

### Issue: TTS Service Not Responding

```bash
# Check TTS containers
docker logs heygem-tts-dual-0
docker logs heygem-tts-dual-1
docker logs heygem-tts-dual-2

# Restart if needed
docker restart heygem-tts-dual-0
docker restart heygem-tts-dual-1
docker restart heygem-tts-dual-2
```

### Issue: GPU Container Stuck (Returns "BUSY")

**Symptoms**: Container always returns "å¿™ç¢Œä¸­" (busy), zombie processes

**Solution**:
```bash
# Check for zombie processes
docker exec heygem-gpu2 ps aux | grep defunct

# Restart the stuck container
docker restart heygem-gpu2

# Wait 30 seconds for initialization
sleep 30

# Verify it's working
curl -s http://localhost:8392/easy/query?code=test123
```

### Issue: GPU Not Found

```bash
# Check GPU visibility
nvidia-smi

# Check container GPU access
docker exec heygem-gpu0 nvidia-smi
docker exec heygem-gpu1 nvidia-smi
docker exec heygem-gpu2 nvidia-smi
```

### Issue: Port Already in Use

```bash
# Find process using port 5003
sudo lsof -i :5003

# Kill process
sudo kill -9 <PID>

# Or use systemd to manage the service
sudo systemctl restart heygem-dual-tts
```

### Issue: Video Not Generating on Specific GPU

```bash
# Check if default.mp4 exists in GPU folder
ls -lh ~/heygem_data/gpu0/default.mp4
ls -lh ~/heygem_data/gpu1/default.mp4
ls -lh ~/heygem_data/gpu2/default.mp4

# Check container can access files
docker exec heygem-gpu0 ls -lh /code/data/
docker exec heygem-gpu1 ls -lh /code/data/
docker exec heygem-gpu2 ls -lh /code/data/

# View container logs for errors
docker logs heygem-gpu0 --tail 50
docker logs heygem-gpu1 --tail 50
docker logs heygem-gpu2 --tail 50
```

---

## ğŸ“ File Structure

```
webapp_dual_tts/
â”œâ”€â”€ app.py                      # Flask API server (Triple GPU)
â”œâ”€â”€ dual_gpu_scheduler.py       # Triple GPU scheduler
â”œâ”€â”€ text_normalization.py       # LaTeX/Math to speech
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html              # Web interface (Triple GPU UI)
â”œâ”€â”€ uploads/                    # User uploaded videos
â”œâ”€â”€ outputs/                    # Generated videos
â”œâ”€â”€ temp/                       # Temporary audio files
â”œâ”€â”€ default.mp4                 # Default video template
â””â”€â”€ reference_audio.wav         # Default voice reference
```

---

## ğŸš€ Advantages Over Other Modes

### vs Dual GPU Mode
- âœ… 50% more throughput (3 vs 2 simultaneous videos)
- âœ… Better GPU utilization
- âœ… Reduced queue wait times

### vs Chunked Mode
- âœ… Simpler architecture (no chunking complexity)
- âœ… Better for short-to-medium videos
- âœ… More reliable (fewer failure points)

---

## ğŸ“ Notes

- **All 3 GPUs active** - maximum parallel processing
- **3 TTS containers** required (ports 18182, 18183, 18184)
- **Smart TTS selection** based on GPU availability
- **Proper queue management** ensures tasks are processed efficiently
- **File stability checks** prevent incomplete file errors

---

## ğŸ¯ Use Cases

**Best for:**
- Production environments requiring maximum throughput
- High-volume video generation workloads
- Scenarios with 3+ available GPUs
- Applications needing minimal latency

**Not recommended for:**
- Systems with only 1-2 GPUs (use dual GPU mode)
- Memory-constrained systems (<16GB VRAM per GPU)
- Long videos requiring chunking (use chunked mode)

---

## ğŸ“ Support

**Check Logs:**
```bash
# Service logs
sudo journalctl -u heygem-dual-tts -f

# Container logs
docker logs heygem-gpu0 -f
docker logs heygem-tts-dual-0 -f

# GPU status
nvidia-smi -l 1
```

**Monitor System:**
- Web UI: `http://localhost:5003`
- Queue API: `http://localhost:5003/api/queue`
- Health Check: `http://localhost:5003/api/health`

---

**Ready to use! Process 3 videos simultaneously! ğŸ‰**
