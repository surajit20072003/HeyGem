#!/usr/bin/env python3
"""
Batch Video Generator - Send 10 parallel requests to test Triple GPU system
Tests concurrent processing across GPU 0, GPU 1, and GPU 2
"""
import requests
import time
import threading
from datetime import datetime

# Configuration
API_URL = "http://localhost:5003/api/generate"
NUM_REQUESTS = 10

# Sample texts for testing
TEST_TEXTS = [
    "Hello everyone, this is video number one from the triple GPU system.",
    "Welcome to the second test video generated by our AI system.",
    "This is the third demonstration of our parallel processing capabilities.",
    "Fourth video showing how multiple GPUs work together seamlessly.",
    "Fifth test video to verify the queue management system.",
    "Sixth video demonstrating the distributed TTS architecture.",
    "Seventh video testing the auto-upload Vimeo integration.",
    "Eighth video showing scalability with three GPUs in parallel.",
    "Ninth video verifying race condition fixes in the scheduler.",
    "Tenth and final video completing our batch test suite."
]

# Results storage
results = []
results_lock = threading.Lock()

def generate_video(index, text):
    """Send a video generation request"""
    task_name = f"Batch_{index+1}"
    
    try:
        print(f"[{task_name}] üì§ Sending request...")
        start_time = time.time()
        
        response = requests.post(
            API_URL,
            data={"text": text},
            timeout=10
        )
        
        elapsed = time.time() - start_time
        
        if response.status_code == 202:
            data = response.json()
            task_id = data.get("task_id")
            
            with results_lock:
                results.append({
                    "index": index,
                    "task_id": task_id,
                    "status": "submitted",
                    "submit_time": elapsed
                })
            
            print(f"[{task_name}] ‚úÖ Submitted - Task ID: {task_id} ({elapsed:.2f}s)")
        else:
            print(f"[{task_name}] ‚ùå Failed - Status: {response.status_code}")
            with results_lock:
                results.append({
                    "index": index,
                    "status": "failed",
                    "error": f"HTTP {response.status_code}"
                })
            
    except Exception as e:
        print(f"[{task_name}] ‚ùå Error: {e}")
        with results_lock:
            results.append({
                "index": index,
                "status": "error",
                "error": str(e)
            })

def check_queue_status():
    """Check current queue status"""
    try:
        response = requests.get("http://localhost:5003/api/queue", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print("\nüìä GPU Status:")
            for gpu_id, gpu_data in sorted(data['gpus'].items()):
                status = "üî¥ BUSY" if gpu_data['busy'] else "üü¢ FREE"
                task = gpu_data.get('current_task', 'None')
                print(f"   GPU {gpu_id}: {status} - Task: {task}")
            print(f"   Queue Size: {data.get('queue_size', 0)}\n")
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not fetch queue status: {e}")

def main():
    print("="*80)
    print("üöÄ Triple GPU Batch Test - Sending 10 Parallel Requests")
    print("="*80)
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Target: {API_URL}")
    print(f"Requests: {NUM_REQUESTS}\n")
    
    # Check initial status
    check_queue_status()
    
    # Create threads for parallel requests
    threads = []
    start_time = time.time()
    
    print("üì§ Sending requests...")
    for i in range(NUM_REQUESTS):
        text = TEST_TEXTS[i] if i < len(TEST_TEXTS) else f"Test video number {i+1}"
        thread = threading.Thread(target=generate_video, args=(i, text))
        thread.start()
        threads.append(thread)
        time.sleep(0.1)  # Small delay to stagger requests
    
    # Wait for all requests to complete
    for thread in threads:
        thread.join()
    
    total_time = time.time() - start_time
    
    # Print summary
    print("\n" + "="*80)
    print("üìä BATCH TEST SUMMARY")
    print("="*80)
    print(f"Total Time: {total_time:.2f}s")
    print(f"Total Requests: {NUM_REQUESTS}")
    
    successful = [r for r in results if r.get('status') == 'submitted']
    failed = [r for r in results if r.get('status') in ['failed', 'error']]
    
    print(f"‚úÖ Submitted: {len(successful)}")
    print(f"‚ùå Failed: {len(failed)}")
    
    if successful:
        print("\n‚úÖ Submitted Tasks:")
        for r in sorted(successful, key=lambda x: x['index']):
            print(f"   Batch_{r['index']+1}: {r['task_id']} ({r['submit_time']:.2f}s)")
    
    if failed:
        print("\n‚ùå Failed Tasks:")
        for r in sorted(failed, key=lambda x: x['index']):
            print(f"   Batch_{r['index']+1}: {r.get('error', 'Unknown error')}")
    
    # Check final queue status
    print("\n" + "="*80)
    time.sleep(2)
    check_queue_status()
    
    print("="*80)
    print("üèÅ Batch test completed!")
    print("="*80)
    print("\nüí° Monitor progress:")
    print("   - Web UI: http://localhost:5003")
    print("   - Queue API: curl http://localhost:5003/api/queue")
    print("   - Logs: sudo journalctl -u heygem-dual-tts -f\n")

if __name__ == "__main__":
    main()
